# red-instruct

| Model           | DangerousQA |            |            |            | HarmfulQA |            |            |            |               |        |        |        |         |                 |
|                 | Standard↓ | CoT↓ | Evaluation↓ | Average↓ | Standard↓ | CoT↓ | Evaluation↓ | Average↓ | Harmless↑ | Honest↑ | Helpful↑ | Others↑ | Average↑ |
|-----------------|-----------|------|-------------|----------|-----------|------|-------------|----------|-----------|---------|---------|---------|----------|----------------|
|                 |           |      |             |          |           |      |             |          |           |         |         |         |          |                |
| GPT-4           | 0         | 0    | 0.651       | 0.217    | 0.001     | 0.004| 0.612       | 0.206    | -         | -       | -       | -        | -              |
| ChatGPT         | 0         | 0.005| 0.728       | 0.244    | 0.018     | 0.027| 0.728       | 0.257    | 0.950     | 0.850   | 0.800   | 0.910    | 0.870          |
| Vicuna-13B      | 0.027     | 0.490| 0.835       | 0.450    | -         | -    | -           | -        | 0.896     | 0.655   | 0.593   | 0.837    | 0.745          |
| Vicuna-7B       | 0.025     | 0.532| 0.875       | 0.477    | -         | -    | -           | -        | 0.689     | 0.590   | 0.559   | 0.697    | 0.634          |
| StableBeluga-13B | 0.026   | 0.630| 0.915       | 0.523    | -         | -    | -           | -        | 0.810     | 0.754   | 0.813   | 0.860    | 0.810          |
| StableBeluga-7B | 0.102    | 0.755| 0.915       | 0.590    | -         | -    | -           | -        | 0.689     | 0.688   | 0.644   | 0.791    | 0.703          |
| Vicuna-FT-7B    | 0.095     | 0.465| 0.860       | 0.473    | -         | -    | -           | -        | 0.689     | 0.623   | 0.559   | 0.721    | 0.648          |
| Llama2-FT-7B    | 0.722     | 0.860| 0.896       | 0.826    | -         | -    | -           | -        | 0.569     | 0.574   | 0.542   | 0.721    | 0.602          |
| (blue)          | 0.015     | 0.485| 0.765       | 0.421    | -         | -    | -           | -        | 0.707     | 0.590   | 0.644   | 0.744    | 0.671          |
| (blue-red)      | 0.050     | 0.570| 0.855       | 0.492    | -         | -    | -           | -        | 0.810     | 0.541   | 0.678   | 0.790    | 0.701          |
|-----------------|-----------|------|-------------|----------|-----------|------|-------------|----------|-----------|---------|---------|---------|----------|----------------|
| Average         | 0.116     | 0.479| 0.830       | 0.471    | 0.010     | 0.016| 0.67        | 0.232    | 0.756     | 0.651   | 0.648   | 0.785    | 0.709          |

DangerousQA shows the attack success rate (ASR) using the standard prompting (Standard), CoT-based prompting (CoT), and CoU-based prompting (Evaluation). A similar evaluation is carried out on 1,960 harmful questions under HarmfulQA. BBH-HHH denotes scores on helpful, honest, harmless, and other data.
